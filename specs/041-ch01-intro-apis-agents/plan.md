# Implementation Plan: Chapter 1 â€” Introduction to AI APIs & OpenAI Agents

**Chapter Branch**: `041-ch01-intro-apis-agents`
**Plan Created**: 2025-12-06
**Plan Status**: Ready for Implementation
**Source Specification**: `spec.md` (32KB, complete requirements)

---

## I. CONTEXT GATHERING & PEDAGOGICAL ANALYSIS

### A. Chapter Identity & Positioning

**Chapter 1 Context**:
- **Position**: Entry point to 16-chapter course on building DocuBot (RAG agent)
- **Student Prerequisite Knowledge**: None (zero programming experience assumed)
- **Complexity Tier**: A1-A2 (Aspiring/Beginner)
- **Duration**: 2-3 hours total (4 lessons Ã— 30-45 minutes each)
- **Hardware Requirements**: All Tier 1 (laptop/cloud only, no GPU/robotics hardware)

**Pedagogical Layer Analysis**:
- **All 4 lessons use Layer 1: Manual Foundation** (conceptual, no agent code yet)
- Rationale: Students need mental models BEFORE implementing agents in Chapter 2
- No Layer 2 (AI Collaboration) in Chapter 1 â€” too early
- No Layer 3 (Intelligence Design) â€” no patterns emerge yet
- No Layer 4 (Spec-Driven Integration) â€” environment not ready yet

**Teaching Modality Approach**:
- Emphasize **analogies over mechanics**: restaurant (API), smart person in room (agent), chef's station (environment), house blueprint (architecture)
- Use **conceptual scaffolding**: minimal code, maximum understanding
- Vary modality across lessons to prevent convergence

### B. Concept Density Analysis

**Core Concepts Identified** (4 per lesson):
```
Lesson 1.1 (API Fundamentals):        4 concepts
  - What APIs are
  - Request/response cycle
  - API keys & authentication
  - JSON data format

Lesson 1.2 (LLM vs Agent):            3 concepts (code-free)
  - LLM capabilities (text-only)
  - Agent capabilities (tools + memory)
  - Why DocuBot needs agents

Lesson 1.3 (Environment Setup):       4 concepts
  - UV package manager
  - Virtual environments
  - Environment variables (.env)
  - Dependency management (pyproject.toml)

Lesson 1.4 (Architecture Overview):   4 concepts (conceptual)
  - System components (Agent, RAG, Backend, Frontend)
  - Component relationships
  - Chapter roadmap
  - Course end goal
```

**Cognitive Load Assessment**:
- **Tier**: A1-A2 (beginner)
- **Concept Count per Lesson**: 3-4 concepts
- **Limit for A1-A2**: ~5-7 concepts per lesson
- **Status**: ALL LESSONS WITHIN LIMIT (heavy scaffolding appropriate)

**Justification for 4 Lessons**:
- Simple concepts (A1-A2 tier) Ã— low code complexity
- 4 lessons justified: Foundation â†’ Verification â†’ Setup â†’ Overview progression
- No arbitrary padding; each lesson has specific learning goal
- Aligns with spec's 2-3 hour total duration

---

## II. LESSON SEQUENCE & PEDAGOGICAL PROGRESSION

### Lesson Progression Arc

```
Lesson 1.1: API Fundamentals (30 min)
  â””â”€ Objective: Understand what APIs are & verify setup works
  â””â”€ Modality: Analogy-driven (restaurant)
  â””â”€ Key Work: Create test_api.py, run it, see response
  â””â”€ Output: Working API key + mental model of request/response

Lesson 1.2: LLM vs Agent Distinction (30 min)
  â””â”€ Objective: Understand why we need agents, not just chatbots
  â””â”€ Modality: Comparison-driven (ChatGPT vs DocuBot capabilities)
  â””â”€ Key Work: Build comparison table
  â””â”€ Output: Clear mental distinction between LLM and Agent
  â””â”€ NOTE: Code-free (Lesson 1.2 is conceptual only)

Lesson 1.3: Environment Setup (40 min)
  â””â”€ Objective: Complete development environment configuration
  â””â”€ Modality: Step-by-step hands-on (but concept-focused)
  â””â”€ Key Work: Install UV, create project, add dependencies, verify
  â””â”€ Output: Fully configured docubot/ folder ready for Chapter 2
  â””â”€ NOTE: Longest lesson (setup has multiple dependencies)

Lesson 1.4: Architecture Overview (30 min)
  â””â”€ Objective: See the big picture â€” what students will build
  â””â”€ Modality: Visualization & documentation (house blueprint)
  â””â”€ Key Work: Create architecture.md with system diagram & roadmap
  â””â”€ Output: Course roadmap + understanding of end-to-end system

Total: ~2.5 hours (within spec's 2-3 hour target)
```

### Stage Transitions (Manual Foundation Only)

**Layer 1 Sequence**:
- Lessons 1.1-1.4 are all Layer 1 (Manual Foundation)
- No student prompt-writing yet (Layer 2 starts in Chapter 2)
- No intelligence creation (Layer 3 starts in Chapter 3+)
- No spec-driven projects (Layer 4 starts in Chapter 9+)

**Transition Readiness for Chapter 2**:
By end of Chapter 1, students will have:
- âœ… Mental model of APIs (Lesson 1.1)
- âœ… Mental model of agents vs LLMs (Lesson 1.2)
- âœ… Working development environment (Lesson 1.3)
- âœ… Understanding of course architecture (Lesson 1.4)
â†’ Ready to write first agent code in Chapter 2 (Layer 1 coding foundation)

---

## III. LESSON-BY-LESSON IMPLEMENTATION PLAN

### LESSON 1.1: API Fundamentals

**Learning Goal**: Students understand what APIs are and verify their OpenAI API key works.

**Pedagogical Layer**: L1 (Manual Foundation)

**Teaching Modality**: Analogy-driven (restaurant service model)

**Hardware Tier**: Tier 1 (all students can access; no special hardware)

**Key Concepts** (4 total, within A1-A2 limit):
1. What APIs are (communication bridges)
2. Request/response cycle (synchronous messaging)
3. API keys (authentication credentials)
4. JSON (data format)

**Cognitive Load Check**: 4 concepts â‰¤ 7 limit for A1-A2 â†’ âœ… PASS

**Content Structure** (follows CSC-001):
```
1. Learning Goal (2 min)
   "By end of this lesson, you'll understand what APIs are and
   have verified your OpenAI API key works."

2. What You'll Learn (3 min)
   - APIs are communication channels between software
   - Your code sends requests, OpenAI responds
   - API keys prove you're authorized to use the service
   - JSON is the language APIs use to talk

3. Key Points (5 min)
   â€¢ APIs are like restaurants: you order (request) â†’ kitchen processes â†’
     waiter brings response
   â€¢ HTTP requests carry what you want (prompt)
   â€¢ OpenAI receives request â†’ processes with AI â†’ sends response
   â€¢ API key is your ID card (authentication)
   â€¢ JSON structures the data

4. Simple Analogy (2 min)
   ğŸ“ THE RESTAURANT ANALOGY
   You go to a restaurant:
   - You (client) ask waiter (API) for food (request)
   - Waiter takes order to kitchen (server)
   - Kitchen (OpenAI) prepares response
   - Waiter brings back food (response with AI text)

   Your code works the same way:
   - Code sends prompt to OpenAI (request)
   - OpenAI processes with AI model (kitchen work)
   - OpenAI sends back completion (response)

5. Code Level (1 min)
   "This lesson introduces minimal code (3-5 lines max).
   You'll import a library, make one API call, see the response.
   No complex programming yetâ€”just proving your setup works."

6. Apply to DocuBot Project (10 min)
   âœ… MANDATORY SECTION (CSC-002, CSC-003)

   ### Task
   Test your OpenAI API key with a simple API call:
   1) Import OpenAI client library
   2) Create OpenAI client instance
   3) Make a simple chat completion call
   4) Print the response

   ### Outcome
   *Confirmed working API key. You see a response from OpenAI,
   proving your development setup is correct.*

7. Hints (6 progressive hints, CSC-003)
   **Hint 1** (Conceptual)
   You need to: import a library, create a client, make a request, print result.
   Can you think of each as a step? âœ“ Reveal Hint 2

   **Hint 2** (Setup)
   From OpenAI documentation, the library is called `openai`.
   You'll import: `from openai import OpenAI`
   âœ“ Reveal Hint 3

   **Hint 3** (Client Creation)
   After importing, create a client with:
   `client = OpenAI()`
   The OpenAI() function reads your API key from environment.
   âœ“ Reveal Hint 4

   **Hint 4** (API Call Structure)
   You need to call: `client.chat.completions.create(...)`
   This needs:
   - `model`: which AI model ("gpt-4o-mini" is cheap for testing)
   - `messages`: list of message objects
   âœ“ Reveal Hint 5

   **Hint 5** (Message Format)
   Each message has role and content:
   ```python
   [{"role": "user", "content": "Say hello"}]
   ```
   âœ“ Reveal Hint 6

   **Hint 6** (Extracting Response)
   The API returns an object. Get the text with:
   `response.choices[0].message.content`
   Print this to see your AI response!

8. Starter Code (optional, after hints, CSC-007)
   ğŸ“ Starter Code:
   ```python
   from openai import OpenAI

   client = OpenAI()

   # Your code here: make a chat completion call
   # Then print the response
   ```

9. Try With AI (implicit in project section)
   Skip for Lesson 1.1â€”students don't prompt AI yet

10. Troubleshooting Notes (edge cases from spec)
    - Invalid API key â†’ 401 error â†’ Instructions to verify key
    - Network timeout â†’ Check internet connection
    - Wrong model name â†’ 404 error â†’ Use "gpt-4o-mini"
    - Extra spaces in .env â†’ Strip whitespace

```

**Estimated Time**: 30 minutes (5 min context + 10 min concepts + 10 min project + 5 min troubleshooting)

**Success Criteria** (maps to SC-001, SC-002):
- Student can articulate API concept using restaurant analogy (SC-001)
- 95% of students successfully run test_api.py on first attempt (SC-002)
- Student sees AI-generated text in terminal

**Constitutional Alignment**:
- âœ… PC-001 (One concept: APIs)
- âœ… PC-002 (LOW cognitive load)
- âœ… PC-003 (Restaurant analogy present)
- âœ… PC-007 (Under 50 min)
- âœ… CSC-001 (Proper section structure)
- âœ… CSC-002 (Apply to DocuBot with Task + Outcome)

---

### LESSON 1.2: LLM vs Agent Distinction

**Learning Goal**: Students understand why DocuBot must be an agent, not just a chatbot.

**Pedagogical Layer**: L1 (Manual Foundation)

**Teaching Modality**: Comparison-driven (capability matrices)

**Hardware Tier**: Tier 1 (conceptual only, no code)

**Key Concepts** (3 total, code-free):
1. LLM capabilities (text generation only)
2. Agent capabilities (tools + memory + actions)
3. Why DocuBot needs agents (document search, context memory, citations)

**Cognitive Load Check**: 3 concepts â‰¤ 7 limit for A1-A2 â†’ âœ… PASS

**Content Structure**:
```
1. Learning Goal (2 min)
   "By end of this lesson, you'll understand why agents are more powerful
   than simple LLMs and why DocuBot must be an agent."

2. What You'll Learn (3 min)
   - LLMs like ChatGPT are powerful but limited
   - Agents have tools and memory that LLMs lack
   - Tools let agents interact with the world (search docs, run code)
   - Memory lets agents remember context across conversations

3. Key Points (5 min)
   â€¢ LLM = text in, text out (like a very smart oracle)
   â€¢ Agent = LLM + tools + memory + decision-making
   â€¢ Tools = superpowers (search documents, calculate, fetch data)
   â€¢ Memory = context preservation across conversations
   â€¢ DocuBot needs all three: search docs + remember context + cite sources

4. Simple Analogy (3 min)
   ğŸ“ SMART PERSON IN A ROOM

   **ChatGPT (LLM)**:
   Imagine a very smart person locked in a room with a slot in the door.
   - You slide in a question through the slot
   - They think deeply and slide back an answer
   - They cannot leave the room, cannot look at your documents,
     cannot use tools, cannot remember you from yesterday
   - Limitation: knowledge cut-off date, no tool use, no memory

   **DocuBot Agent**:
   Same smart person BUT now they have:
   - **Tools**: Phone to call libraries, computer to search your documents,
     paper to take notes
   - **Memory**: A notebook to remember your earlier questions and answers
   - **Agency**: Can decide what tool to use when
   - Capability: Can find answers in YOUR documents, remember context,
     cite sources

5. Code Level (1 min)
   "This lesson is PURELY CONCEPTUAL. No code. We're building mental models
   that will guide agent design in future chapters."

6. Apply to DocuBot Project (15 min)
   âœ… MANDATORY SECTION (CSC-002)

   ### Task
   Create a comparison table with two columns showing capabilities:
   1) "What ChatGPT Can Do" â€” list 5+ things ChatGPT is good at
   2) "What DocuBot Agent Will Do" â€” list 5+ agent capabilities
   3) For each row, show the capability difference that justifies agents

   ### Outcome
   *A clear comparison showing that DocuBot needs to be an agent because
   it must search documents, remember context, and cite sourcesâ€”capabilities
   simple LLMs don't have.*

7. Hints (6 progressive hints)
   **Hint 1** (Framework)
   Think about two columns:
   - Column 1: ChatGPT strengths (general knowledge)
   - Column 2: DocuBot strengths (specific to your documents)
   âœ“ Reveal Hint 2

   **Hint 2** (ChatGPT Examples)
   ChatGPT can:
   - Answer general knowledge questions
   - Write creative content
   - Explain concepts
   - Translate languages
   - Have conversations
   âœ“ Reveal Hint 3

   **Hint 3** (ChatGPT Limitations)
   ChatGPT CANNOT:
   - Access your specific documents
   - Remember conversations from yesterday
   - Know about your company's internal data
   - Cite which document an answer came from
   âœ“ Reveal Hint 4

   **Hint 4** (DocuBot Agent Examples)
   DocuBot Agent CAN:
   - Search your document collection
   - Remember your conversation context
   - Cite source documents
   - Learn from your feedback
   - Answer questions about your specific content
   âœ“ Reveal Hint 5

   **Hint 5** (Capability Pairs)
   Try these rows in your table:
   - General knowledge vs Domain knowledge
   - Stateless conversation vs Context memory
   - Generic answers vs Cited answers
   - Static knowledge vs Access to live documents
   âœ“ Reveal Hint 6

   **Hint 6** (Making It Real)
   For each row, ask yourself:
   "Why does DocuBot need this capability?"
   Example:
   Row 1: ChatGPT: "General knowledge"; DocuBot: "Domain knowledge"
   Why? Because users want answers about THEIR documents, not internet

```

**Estimated Time**: 35 minutes (5 min context + 8 min concepts + 15 min project + 7 min review)

**Success Criteria** (maps to SC-003):
- Student completes comparison table with 5+ items per column (SC-003)
- Table shows meaningful capability differences (not duplicates)
- Student can articulate: "Agents have tools and memory that LLMs lack"

**Constitutional Alignment**:
- âœ… PC-001 (One concept: LLM vs Agent distinction)
- âœ… PC-002 (LOW cognitive load, no code)
- âœ… PC-003 (Smart person in room analogy)
- âœ… PC-004 (Code-free as required)
- âœ… PC-007 (Under 50 min)
- âœ… CSC-001 (Proper structure)
- âœ… CSC-002 (Apply to DocuBot with Task + Outcome)

---

### LESSON 1.3: Environment Setup

**Learning Goal**: Students install UV, create project folder, configure .env, and verify everything works.

**Pedagogical Layer**: L1 (Manual Foundation)

**Teaching Modality**: Step-by-step hands-on (process-oriented, like following a recipe)

**Hardware Tier**: Tier 1 (works on all OS: macOS, Linux, Windows)

**Key Concepts** (4 total):
1. UV package manager (modern Python packaging)
2. Virtual environments (isolated project dependencies)
3. Environment variables (.env files for secrets)
4. Dependency management (pyproject.toml)

**Cognitive Load Check**: 4 concepts â‰¤ 7 limit for A1-A2 â†’ âœ… PASS

**Content Structure**:
```
1. Learning Goal (2 min)
   "By end of this lesson, you'll have a fully configured Python project
   with UV, virtual environment, OpenAI library, and API key ready for
   Chapter 2 coding."

2. What You'll Learn (3 min)
   - UV is a modern Python package manager (replaces pip)
   - Virtual environments isolate project dependencies
   - .env files store secrets safely (API keys)
   - pyproject.toml declares what your project needs

3. Key Points (5 min)
   â€¢ UV is fast and modern (we use it instead of pip/poetry)
   â€¢ Virtual environment = sandboxed Python with project-specific packages
   â€¢ .env = security: API keys never in version control
   â€¢ pyproject.toml = reproducibility: others install same versions
   â€¢ Order matters: UV â†’ virtual env â†’ .env â†’ openai library

4. Simple Analogy (2 min)
   ğŸ“ CHEF'S COOKING STATION

   Your project is like a chef's station:
   - **UV**: The prep list (tools you need)
   - **Virtual environment**: The dedicated station (isolated workspace)
   - **.env file**: The recipe card (your ingredients/secrets)
   - **pyproject.toml**: The ingredient list (what's installed)
   - **Code files**: Your actual cooking (happens in Chapter 2)

   Just like each chef station has its own tools and ingredients,
   each project has its own dependencies and configuration.

5. Code Level (2 min)
   "This lesson is mostly CLI commands, no Python code yet. You'll run
   shell/terminal commands to set up your environment. No programming logic."

6. Apply to DocuBot Project (20 min)
   âœ… MANDATORY SECTION (CSC-002)

   ### Task
   Follow the environment setup guide to prepare your system:
   1) Install UV using the OS-specific command
   2) Create docubot project folder
   3) Initialize UV project (creates pyproject.toml and uv.lock)
   4) Create .env file with your OpenAI API key
   5) Run uv add openai to install the library
   6) Verify with: python -c "from openai import OpenAI"

   ### Outcome
   *A fully configured docubot/ project folder with UV, virtual environment,
   .env file, and OpenAI library installed and verified. Your environment
   is ready for Chapter 2 coding.*

7. OS-Specific Installation Instructions (split by OS)

   ğŸ“± macOS & Linux:
   ```bash
   # 1. Install UV
   curl -LsSf https://astral.sh/uv/install.sh | sh

   # 2. Verify installation
   uv --version

   # 3. Create project folder
   mkdir docubot
   cd docubot

   # 4. Initialize UV project
   uv init

   # 5. Create .env file
   touch .env
   # Then open .env in your editor and add:
   # OPENAI_API_KEY=sk-...your-key-here...

   # 6. Install OpenAI library
   uv add openai

   # 7. Verify it works
   python -c "from openai import OpenAI; print('Success!')"
   ```

   ğŸªŸ Windows (PowerShell):
   ```powershell
   # 1. Install UV via PowerShell
   powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"

   # 2. Verify installation
   uv --version

   # 3. Create project folder
   mkdir docubot
   cd docubot

   # 4. Initialize UV project
   uv init

   # 5. Create .env file
   New-Item .env -ItemType File
   # Then open .env in your editor and add:
   # OPENAI_API_KEY=sk-...your-key-here...

   # 6. Install OpenAI library
   uv add openai

   # 7. Verify it works
   python -c "from openai import OpenAI; print('Success!')"
   ```

8. .env File Setup (5 min explanation)

   Why .env?
   - API keys should NEVER be in code
   - .env file stays local (never committed to git)
   - Python libraries automatically read .env when present

   Format (exactly):
   ```
   OPENAI_API_KEY=sk-proj-...your-key-here...
   ```

   âš ï¸ Common mistakes:
   - Extra spaces: `OPENAI_API_KEY = sk-...` â†’ Wrong (space before =)
   - Extra quotes: `OPENAI_API_KEY="sk-..."` â†’ Wrong (quotes not needed)
   - Incomplete key: `OPENAI_API_KEY=sk-` â†’ Wrong (copy full key)

9. Hints (6 progressive hints)
   **Hint 1** (Big Picture)
   Four things to do:
   1. Install UV
   2. Create project folder
   3. Initialize project with UV
   4. Add OpenAI library
   âœ“ Reveal Hint 2

   **Hint 2** (Install UV)
   UV is installed via a script. For macOS/Linux:
   `curl -LsSf https://astral.sh/uv/install.sh | sh`
   For Windows PowerShell, use the PowerShell version provided.
   âœ“ Reveal Hint 3

   **Hint 3** (Verify Installation)
   After install, check it worked:
   `uv --version`
   You should see a version number like "0.4.x"
   âœ“ Reveal Hint 4

   **Hint 4** (Project Setup)
   Create folder: `mkdir docubot`
   Enter folder: `cd docubot`
   Initialize: `uv init`
   This creates pyproject.toml and uv.lock files.
   âœ“ Reveal Hint 5

   **Hint 5** (.env File)
   Create: `touch .env` (macOS/Linux) or `New-Item .env` (Windows)
   Edit file and add:
   OPENAI_API_KEY=sk-...your-actual-key...
   (Get key from: https://platform.openai.com/api-keys)
   âœ“ Reveal Hint 6

   **Hint 6** (Verify Everything)
   Install library: `uv add openai`
   Test import: `python -c "from openai import OpenAI; print('OK')"`
   If you see "OK", your setup is complete!

10. Verification Checklist (after setup)
    Students should verify:
    - [ ] `uv --version` returns a version number
    - [ ] `python --version` returns 3.8+
    - [ ] `docubot/` folder exists
    - [ ] `docubot/pyproject.toml` exists
    - [ ] `docubot/.env` exists with OPENAI_API_KEY set
    - [ ] `python -c "from openai import OpenAI"` succeeds
    - [ ] Can run `test_api.py` from Lesson 1.1 in docubot/ folder

```

**Estimated Time**: 40-45 minutes (longest lesson due to installation dependencies)
- 5 min: concept explanation
- 25 min: hands-on installation (actual time varies by OS/network)
- 10 min: verification and troubleshooting
- 5 min: review and next steps

**Success Criteria** (maps to SC-004, SC-005):
- Student installs UV in under 30 minutes (SC-004)
- 90% complete setup without instructor help (SC-005)
- All verification checks pass

**Constitutional Alignment**:
- âœ… PC-001 (One concept: Environment Setup)
- âœ… PC-003 (Chef's station analogy)
- âœ… PC-007 (Under 50 min, though close)
- âœ… CSC-001 (Proper structure)
- âœ… CSC-002 (Apply to DocuBot with Task + Outcome)
- âœ… TC-003 (Cross-platform OS instructions)
- âœ… TC-004 (Uses UV, not pip)

---

### LESSON 1.4: Architecture Overview

**Learning Goal**: Students see the complete system architecture and understand which chapter builds which component.

**Pedagogical Layer**: L1 (Manual Foundation)

**Teaching Modality**: Visualization + documentation (big-picture thinking)

**Hardware Tier**: Tier 1 (conceptual, no code)

**Key Concepts** (4 total, high-level):
1. System components (Agent, RAG Pipeline, Backend, Frontend)
2. Component relationships (how they connect)
3. Chapter roadmap (which chapter builds what)
4. Course end goal (what students will have built)

**Cognitive Load Check**: 4 concepts â‰¤ 7 limit for A1-A2 â†’ âœ… PASS

**Content Structure**:
```
1. Learning Goal (2 min)
   "By end of this lesson, you'll see the complete DocuBot system architecture
   and understand what you're building across the 16-chapter course."

2. What You'll Learn (3 min)
   - DocuBot has 4 main parts: Agent, RAG Pipeline, Backend API, Frontend
   - Each part works together to create a document-searching chatbot
   - You'll build components progressively across chapters
   - By Chapter 16, you'll have a complete, deployable system

3. Key Points (5 min)
   â€¢ Agent = the brain (responds to questions, remembers context)
   â€¢ RAG Pipeline = the librarian (finds answers in your documents)
   â€¢ Backend = the server (routes requests, manages logic)
   â€¢ Frontend = the interface (what users interact with)
   â€¢ Together = complete system that searches documents and provides citations

4. Simple Analogy (3 min)
   ğŸ“ HOUSE BLUEPRINT

   Before building a house, you need a blueprint showing:
   - Overall structure (how many rooms)
   - How rooms connect (doors, hallways)
   - What each room does (kitchen, bedroom)

   DocuBot is like a house:
   - **Agent** = Brain (decision center)
   - **RAG** = Library (stores and searches documents)
   - **Backend** = Infrastructure (plumbing, electricity)
   - **Frontend** = Entryway (how visitors interact)

   This lesson is the blueprint. Later chapters build each room.

5. Code Level (1 min)
   "This lesson is PURELY CONCEPTUAL. No code. You'll create a Markdown
   document with diagrams and descriptions. This document guides your work
   through all 16 chapters."

6. Apply to DocuBot Project (15 min)
   âœ… MANDATORY SECTION (CSC-002)

   ### Task
   Create architecture.md file in your docubot/ folder with three sections:
   1) System Overview â€” ASCII/text diagram showing component flow
   2) Component Descriptions â€” what each component does (1-2 sentences each)
   3) Chapter Roadmap â€” which chapters build which components

   ### Outcome
   *A documented architecture that serves as your roadmap for the entire
   course. You can see the end goal and understand which chapter builds
   which piece of the system.*

7. System Overview Diagram (text-based)
   ```
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                                                           â”‚
   â”‚                    USER INTERFACE                         â”‚
   â”‚              (Frontend â€” Chapter 12-13)                   â”‚
   â”‚           ChatKit Web/Mobile Application                  â”‚
   â”‚                                                           â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ (HTTP requests/responses)
                       â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                                                           â”‚
   â”‚                   BACKEND API                             â”‚
   â”‚            (FastAPI â€” Chapter 12-13)                      â”‚
   â”‚        Routes requests, manages workflows                 â”‚
   â”‚                                                           â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ (function calls)
                       â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                    AGENT (Brain)                          â”‚
   â”‚           (OpenAI Agents SDK â€” Ch 1-9)                    â”‚
   â”‚      Thinks, decides, remembers context, takes actions    â”‚
   â”‚                                                           â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚                  â”‚
        (search docs) â”‚                  â”‚ (function calls)
                       â–¼                  â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   RAG PIPELINE             â”‚  â”‚   TOOLS & FUNCTIONS  â”‚
   â”‚  (Semantic Search)         â”‚  â”‚  (Agent's abilities) â”‚
   â”‚  (Ch 10-11)                â”‚  â”‚  (Ch 4-9)            â”‚
   â”‚  Vector DB + Embedding     â”‚  â”‚                      â”‚
   â”‚                            â”‚  â”‚                      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   ```

8. Component Descriptions

   **Agent (Brain)**
   - Thinks about questions
   - Remembers conversation context
   - Decides which tools to use
   - Generates responses

   **RAG Pipeline (Librarian)**
   - Converts documents to searchable format
   - Finds relevant documents for each query
   - Returns context for Agent to reference

   **Backend API (Coordinator)**
   - Receives user messages
   - Calls Agent to think
   - Calls RAG to search documents
   - Returns response to frontend

   **Frontend (Entryway)**
   - User types message
   - Displays AI response and citations
   - Manages conversation history
   - Beautiful, responsive interface

9. Chapter Roadmap
   ```
   CHAPTER 1-3: Agent Basics
   â””â”€ Understand APIs, agents, environment setup
   â””â”€ Build: Manual foundation, mental models

   CHAPTER 4-9: Advanced Agent Features
   â””â”€ Tools, function calling, memory patterns
   â””â”€ Build: Sophisticated agent behaviors

   CHAPTER 10-11: RAG Pipeline
   â””â”€ Vector embeddings, semantic search
   â””â”€ Build: Document indexing and retrieval

   CHAPTER 12-13: Frontend & Backend
   â””â”€ FastAPI, ChatKit, integrations
   â””â”€ Build: User interface and server infrastructure

   CHAPTER 14-16: Production & Deployment
   â””â”€ Monitoring, scaling, cost optimization
   â””â”€ Build: Deployment pipelines, production safety

   END RESULT: Complete DocuBot system
   â””â”€ RAG chatbot that searches user documents
   â””â”€ Provides cited answers with sources
   â””â”€ Production-ready deployment
   ```

10. Hints (6 progressive hints)
    **Hint 1** (Big Picture)
    Think: What does DocuBot do?
    Answer: Searches documents and answers questions about them.
    What does that require?
    âœ“ Reveal Hint 2

    **Hint 2** (Components)
    To search documents and answer questions, you need:
    - Something that THINKS (Agent)
    - Something that SEARCHES (RAG)
    - Something that COORDINATES (Backend)
    - Something that SHOWS results (Frontend)
    âœ“ Reveal Hint 3

    **Hint 3** (Agent Role)
    Agent = brain. It:
    - Understands questions
    - Remembers previous questions
    - Decides what tools to use
    - Generates answers
    âœ“ Reveal Hint 4

    **Hint 4** (RAG Role)
    RAG = librarian. It:
    - Knows where to find information
    - Searches through documents
    - Returns relevant passages
    - Cites sources
    âœ“ Reveal Hint 5

    **Hint 5** (Backend & Frontend)
    Backend = coordinator between Agent and RAG
    Frontend = what users see and interact with
    âœ“ Reveal Hint 6

    **Hint 6** (Chapter Mapping)
    Chapters 1-3: Learn basics
    Chapters 4-9: Build Agent abilities
    Chapters 10-11: Build RAG system
    Chapters 12-13: Build Backend & Frontend
    Chapters 14-16: Production & deployment

11. Sample architecture.md Structure
    (Students will create similar file)
    ```markdown
    # DocuBot Architecture

    ## System Overview

    [Include ASCII diagram from Hint 7 above]

    User's Question
      â†“
    Frontend (ChatKit) â€” User interface
      â†“
    Backend API (FastAPI) â€” Coordinator
      â†“
    Agent (OpenAI) + RAG (Vector Search)
      â†“
    Response with cited sources

    ## Component Descriptions

    ### 1. Frontend (User Interface)
    ChatKit web application where users type questions
    and see responses with source citations.

    ### 2. Backend API
    FastAPI server that coordinates between frontend,
    agent, and RAG pipeline.

    ### 3. Agent (Brain)
    OpenAI Agent that understands questions,
    remembers context, decides which tools to use.

    ### 4. RAG Pipeline (Librarian)
    Vector database + embedding model that indexes
    documents and retrieves relevant passages.

    ## Chapter Roadmap

    | Chapters | Component | What You Build |
    |----------|-----------|----------------|
    | 1-3 | Foundation | Mental models, setup, first concepts |
    | 4-9 | Agent | Tools, memory, behaviors |
    | 10-11 | RAG | Vector DB, embeddings, search |
    | 12-13 | Backend & Frontend | APIs, UI |
    | 14-16 | Production | Deployment, monitoring, scaling |
    ```

```

**Estimated Time**: 35 minutes
- 5 min: concept explanation
- 8 min: learning the analogy and system overview
- 15 min: creating architecture.md
- 7 min: reflection on course journey

**Success Criteria** (maps to SC-006, SC-009):
- Student creates architecture.md with all 3 sections (SC-006)
- Student can articulate: "I'm building a RAG chatbot that searches documents
  and provides cited answers" (SC-009)
- File includes component diagram, descriptions, and chapter roadmap

**Constitutional Alignment**:
- âœ… PC-001 (One concept: System Architecture)
- âœ… PC-002 (LOW cognitive load)
- âœ… PC-003 (House blueprint analogy)
- âœ… PC-007 (Under 50 min)
- âœ… CSC-001 (Proper structure)
- âœ… CSC-002 (Apply to DocuBot with Task + Outcome)

---

## IV. CUMULATIVE DOCUBOT PROJECT STATE

### After Chapter 1 Completion

**What Students Have Built**:
```
docubot/
â”œâ”€â”€ pyproject.toml              (UV project manifest)
â”œâ”€â”€ uv.lock                     (Locked dependencies)
â”œâ”€â”€ .env                        (API key â€” not in git)
â”œâ”€â”€ .gitignore                  (Excludes .env)
â”œâ”€â”€ test_api.py                 (From Lesson 1.1)
â”œâ”€â”€ llm_vs_agent_table.md       (From Lesson 1.2)
â””â”€â”€ architecture.md             (From Lesson 1.4)
```

**Mental Models Established**:
1. âœ… APIs are communication channels (restaurant analogy)
2. âœ… Agents differ from LLMs (smart person analogy)
3. âœ… Development environment is configured
4. âœ… Course endpoint is clear (DocuBot system)

**Readiness for Chapter 2**:
- âœ… API key works (verified in Lesson 1.1)
- âœ… UV environment ready (verified in Lesson 1.3)
- âœ… Mental models established (Lessons 1.1-1.2)
- âœ… Architecture understood (Lesson 1.4)
â†’ **Ready to write first agent code in Chapter 2**

**Chapter 1 Outcomes Summary** (CSC-005):
- Lesson 1.1 outcome: *Confirmed working API key*
- Lesson 1.2 outcome: *Clear LLM vs Agent distinction understood*
- Lesson 1.3 outcome: *Fully configured development environment*
- Lesson 1.4 outcome: *Course roadmap documented*

All four outcomes show progression toward complete DocuBot system.

---

## V. HARDWARE TIER ANALYSIS

### Tier 1 (Default) â€” ALL Lessons Compatible

**Hardware Requirements**:
- Any modern laptop/desktop (macOS, Windows, Linux)
- 1GB free disk space
- Internet access (for API calls)
- Code editor (VS Code recommended, not required)

**Cost**:
- Lesson 1.1: ~$0.01 (one API call)
- Lesson 1.3: ~$0 (dependencies are free/open-source)
- Lesson 1.4: ~$0 (documentation only)

**No Special Hardware Needed**:
- No GPU required (API calls go to OpenAI's servers)
- No robotics hardware
- No specialized cloud setup

**Tier 2+ Fallbacks**:
- Not applicable for Chapter 1 (no special tiers needed)

**Accessibility Notes**:
- Windows users get PowerShell-specific UV install instructions
- macOS/Linux use standard curl commands
- All students use same .env approach (cross-platform)

---

## VI. INTELLIGENCE CREATION OPPORTUNITIES

### Analysis: Should Chapter 1 Create Any Skills/Subagents?

**Skill Eligibility Criteria** (from Constitution Section V):
1. **Frequency**: Does pattern recur 2+ times?
   - Lesson 1.1 API testing: Only in Lesson 1.1 (not recurring yet)
   - Lesson 1.3 environment setup: One-time setup
   - Result: âŒ No patterns recur

2. **Complexity**: Does it involve 5+ decision points?
   - API testing: 3 decisions (import, create client, call API)
   - Environment setup: 4 decisions (install UV, create folder, add .env, install library)
   - Result: âŒ Insufficient complexity for skill

3. **Organizational Value**: Will this apply 3+ future projects?
   - API testing pattern too simple (one-off verification)
   - Environment setup is one-time per course
   - Result: âŒ Limited reuse value

**Conclusion**: **NO skills or subagents created in Chapter 1**

**Rationale**:
- Chapter 1 is purely foundational and conceptual
- Patterns don't recur yet (would need Chapter 2-3 to see recurrence)
- Intelligence design starts in Chapter 3+ when patterns emerge
- Creating skills prematurely adds overhead without value

**First Intelligence Creation**:
â†’ Occurs in **Chapter 2-3** when students see first agent patterns recur

---

## VII. VALIDATION & ACCEPTANCE TESTS

### Chapter 1 Success Metrics

**Test 1: Lesson 1.1 API Verification** âœ…
```
Given: Student with valid OpenAI API key
When: Follows Lesson 1.1 to create test_api.py
Then:
  âœ“ Script executes without errors
  âœ“ AI response prints to terminal
  âœ“ Response is coherent (not garbage)
  âœ“ Student understands restaurant analogy
```

**Test 2: Lesson 1.2 Conceptual Understanding** âœ…
```
Given: Student completes LLM vs Agent table
When: Table is reviewed
Then:
  âœ“ ChatGPT column lists 5+ limitations
  âœ“ DocuBot column lists 5+ agent capabilities
  âœ“ Columns show distinction (not duplicates)
  âœ“ Student can explain: "Agents have tools, LLMs don't"
```

**Test 3: Lesson 1.3 Environment Completeness** âœ…
```
Given: Student follows setup instructions
When: Setup is verified
Then:
  âœ“ `uv --version` returns version number
  âœ“ `python --version` returns 3.8+
  âœ“ docubot/ folder exists with pyproject.toml
  âœ“ .env contains OPENAI_API_KEY
  âœ“ `from openai import OpenAI` succeeds
  âœ“ test_api.py from Lesson 1.1 works in docubot/
```

**Test 4: Lesson 1.4 Architecture Documentation** âœ…
```
Given: Student creates architecture.md
When: File is reviewed
Then:
  âœ“ Section 1: System Overview with component diagram
  âœ“ Section 2: Component Descriptions (5+ components)
  âœ“ Section 3: Chapter Roadmap (Ch 1-3, 4-9, 10-11, 12-13, 14-16)
  âœ“ Student explains end goal: "RAG chatbot with citations"
```

**Test 5: DocuBot Project Section Compliance** âœ…
```
Given: All 4 lessons implemented
When: Content audited for format
Then:
  âœ“ Every lesson has "ğŸ¤– Apply to DocuBot Project"
  âœ“ Each section has Task (numbered steps)
  âœ“ Each section has Outcome (italicized)
  âœ“ Outcomes show cumulative progress
  âœ“ Lesson 1.1 outcome â†’ verified API key
  âœ“ Lesson 1.2 outcome â†’ understood distinction
  âœ“ Lesson 1.3 outcome â†’ environment configured
  âœ“ Lesson 1.4 outcome â†’ architecture documented
```

**Test 6: Chapter 1 Completion Criteria** âœ…
```
Given: Student completes all 4 lessons
When: Chapter assessment conducted
Then:
  âœ“ All 4 lesson outcomes marked complete
  âœ“ Total time: 2-3 hours
  âœ“ Zero agent code written (conceptual only)
  âœ“ Student articulates: "Building DocuBot RAG chatbot"
  âœ“ Student scores 80%+ on concept quiz
```

---

## VIII. IMPLEMENTATION CHECKLIST FOR CONTENT CREATORS

### Pre-Implementation (Context & Planning)

- [ ] Read this plan.md completely
- [ ] Read spec.md to understand all requirements
- [ ] Read Constitution Section IIa (4-Layer framework)
- [ ] Verify understanding: All lessons are L1 (Manual Foundation)
- [ ] Confirm: No agent code in Chapter 1 (TC-001)

### Lesson 1.1 Implementation

**Content Creation**:
- [ ] Write "Learning Goal" section (2 min read)
- [ ] Write "What You'll Learn" section (3 min)
- [ ] Write "Key Points" with 4 core concepts (5 min)
- [ ] Create restaurant analogy box/blockquote
- [ ] Explain code level (minimal 3-5 lines)
- [ ] Write ApplyToDocuBot section with Task + Outcome
  - [ ] Task has 4 numbered steps
  - [ ] Outcome is italicized statement
- [ ] Create 6 progressive hints (Hint 1 vague â†’ Hint 6 specific)
- [ ] Create starter code after hints (3-5 lines)

**Code Validation**:
- [ ] Test test_api.py locally with valid API key
- [ ] Verify it returns valid response from OpenAI
- [ ] Document API call time (should be <5 sec)
- [ ] Test with invalid API key â†’ verify error message
- [ ] Test with network timeout â†’ document behavior

**Quality Checks**:
- [ ] Spell-check and grammar review
- [ ] Verify all code blocks have syntax highlighting
- [ ] Check: No meta-commentary (no "What to notice")
- [ ] Confirm: Restaurant analogy present
- [ ] Estimate: Can complete in ~30 minutes

### Lesson 1.2 Implementation

**Content Creation**:
- [ ] Write Learning Goal section
- [ ] Write What You'll Learn section (code-free focus)
- [ ] Write Key Points (3 concepts, not 4)
- [ ] Create "smart person in room" analogy box
- [ ] Emphasize: ZERO CODE in this lesson
- [ ] Write Apply to DocuBot section
  - [ ] Task: Create comparison table with 5+ rows
  - [ ] Outcome: Italicized statement about distinction
- [ ] Create 6 progressive hints
  - [ ] Hint 1: Framework (two columns)
  - [ ] Hints 2-3: ChatGPT examples
  - [ ] Hints 4-5: DocuBot examples
  - [ ] Hint 6: Making it real

**Content Validation**:
- [ ] Confirm: Zero Python code in lesson
- [ ] Check: Analogy maps clearly (person locked in room â†’ has tools)
- [ ] Verify: Comparison table format is clear
- [ ] Check: No meta-commentary

**Quality Checks**:
- [ ] Spell-check and grammar
- [ ] Estimate: Can complete in ~35 minutes
- [ ] Accessible to beginner with no programming experience

### Lesson 1.3 Implementation

**Content Creation**:
- [ ] Write Learning Goal section
- [ ] Write What You'll Learn section
- [ ] Write Key Points (4 concepts)
- [ ] Create "chef's station" analogy
- [ ] Write Code Level (mostly CLI, not programming)
- [ ] Create OS-specific installation instructions
  - [ ] macOS/Linux with curl command
  - [ ] Windows with PowerShell command
- [ ] Write .env file setup instructions
  - [ ] Exact format shown
  - [ ] Common mistakes listed
- [ ] Write Apply to DocuBot section
  - [ ] Task: 6 numbered steps (install UV â†’ verify)
  - [ ] Outcome: Italicized statement about configuration
- [ ] Create 6 progressive hints
  - [ ] Hint 1: Big picture (4 steps)
  - [ ] Hints 2-4: Installation process
  - [ ] Hint 5: .env file setup
  - [ ] Hint 6: Verification commands
- [ ] Create verification checklist

**Command Validation**:
- [ ] Test UV installation on macOS
- [ ] Test UV installation on Windows (PowerShell)
- [ ] Test UV installation on Linux
- [ ] Verify: `uv init` creates pyproject.toml + uv.lock
- [ ] Verify: `.env` loading works (if using python-dotenv)
- [ ] Verify: `uv add openai` installs library successfully
- [ ] Verify: `from openai import OpenAI` imports without error
- [ ] Test: test_api.py from Lesson 1.1 works in docubot/ folder

**Platform Compatibility**:
- [ ] Windows path separators work (\ vs /)
- [ ] PowerShell execution policy handled
- [ ] Environment variable loading works cross-platform
- [ ] .env file works on all OSes

**Quality Checks**:
- [ ] Spell-check and grammar
- [ ] Installation instructions are clear
- [ ] No ambiguous steps
- [ ] Estimate: 40-45 minutes (longest lesson)
- [ ] Troubleshooting tips provided

### Lesson 1.4 Implementation

**Content Creation**:
- [ ] Write Learning Goal section
- [ ] Write What You'll Learn section (high-level)
- [ ] Write Key Points (4 concepts, architectural)
- [ ] Create "house blueprint" analogy
- [ ] Emphasize: ZERO CODE, architecture only
- [ ] Create system overview diagram
  - [ ] ASCII box diagram showing flow
  - [ ] Include: Frontend â†’ Backend â†’ Agent â†’ RAG
- [ ] Write component descriptions (1-2 sentences each)
  - [ ] Agent (brain)
  - [ ] RAG Pipeline (librarian)
  - [ ] Backend (coordinator)
  - [ ] Frontend (entryway)
- [ ] Create chapter roadmap
  - [ ] Ch 1-3: Agent basics
  - [ ] Ch 4-9: Advanced features
  - [ ] Ch 10-11: RAG pipeline
  - [ ] Ch 12-13: Frontend/Backend
  - [ ] Ch 14-16: Production
- [ ] Write Apply to DocuBot section
  - [ ] Task: Create architecture.md with 3 sections
  - [ ] Outcome: Italicized statement about roadmap
- [ ] Create 6 progressive hints
  - [ ] Hint 1: Big picture (what does DocuBot do?)
  - [ ] Hint 2: 4 components needed
  - [ ] Hints 3-5: Role of each component
  - [ ] Hint 6: Chapter mapping

**Diagram Validation**:
- [ ] ASCII diagram is clear and readable
- [ ] All 4 components shown
- [ ] Data flow is visible
- [ ] Alternative text description available

**Content Quality**:
- [ ] Component descriptions non-technical (no implementation details)
- [ ] Chapter roadmap is accurate
- [ ] Analogy maps to architecture (rooms = components)
- [ ] End goal is clear: "RAG chatbot with citations"

**Quality Checks**:
- [ ] Spell-check and grammar
- [ ] Estimate: ~35 minutes
- [ ] Accessible to absolute beginner

### Cross-Lesson Quality Assurance

**Format Compliance**:
- [ ] All lessons follow CSC-001 (Learning Goal â†’ Concept â†’ Key Points â†’ Analogy â†’ Code Level â†’ Apply â†’ Outcome â†’ Hints)
- [ ] All Apply sections have Task + Outcome (CSC-002)
- [ ] Task sections use numbered steps (CSC-003)
- [ ] Outcome sections are italicized (CSC-004)
- [ ] All hints are 6 in number (CSC-006)

**Content Consistency**:
- [ ] All 4 lessons are documented in Apply sections
- [ ] Cumulative progress visible (Lesson 1 â†’ 2 â†’ 3 â†’ 4)
- [ ] DocuBot project state evolves naturally
- [ ] No content duplication between lessons

**Constitutional Alignment**:
- [ ] Each lesson teaches ONE concept (PC-001)
- [ ] Cognitive load appropriate for A1-A2 (PC-002)
- [ ] All analogies present and coherent (PC-003)
- [ ] Lesson 1.2 is completely code-free (PC-004)
- [ ] Concept â†’ Apply separation clear (PC-005)
- [ ] All hints are progressive (PC-006)
- [ ] All lessons under 50 minutes (PC-007)

**Constraint Compliance**:
- [ ] NO agent code anywhere (TC-001)
- [ ] Code examples minimal (TC-002)
- [ ] OS-specific instructions provided (TC-003)
- [ ] UV used, not pip/poetry (TC-004)
- [ ] API calls use gpt-4o-mini (TC-005)

**Dependency Validation**:
- [ ] DC-001: No prerequisites (independent entry point)
- [ ] DC-002: Lesson 1.1 before 1.3 (API key before env setup)
- [ ] DC-003: Chapter 1 before Chapter 2 (environment prerequisite)
- [ ] DC-004: Chapter gating enforced (if platform supports)

**Success Criteria Mapping**:
- [ ] SC-001: Restaurant analogy for API explanation
- [ ] SC-002: 95% successful test_api.py on first try
- [ ] SC-003: Comparison table with 5+ items per column
- [ ] SC-004: Environment setup in under 30 min
- [ ] SC-005: 90% completion without instructor help
- [ ] SC-006: architecture.md with 3 required sections
- [ ] SC-007: Chapter completion in 2-3 hours
- [ ] SC-008: Zero agent code (verify no Agent class, no Runner)
- [ ] SC-009: Students articulate course end goal
- [ ] SC-010: 100% have working API key + environment

### Final Review Checklist

**Before Marking Complete**:
- [ ] All content written and edited
- [ ] All code examples tested
- [ ] All commands verified on target OSes
- [ ] All analogies clearly explained
- [ ] All hints are progressive (vague â†’ specific)
- [ ] No meta-commentary (search: "What to notice", "Layer", "Three Roles")
- [ ] All DocuBot project sections complete
- [ ] Total time estimate: ~2-3 hours
- [ ] Ready for technical review

---

## IX. CONTENT IMPLEMENTER WORKFLOW

### 4-Stage Implementation Process

**Stage 1: Lesson Skeleton** (1 hour per lesson)
```
- Copy lesson template from CSC-001
- Fill in Learning Goal, Concept, Key Points
- Write simple analogy box
- Create placeholder for Apply to DocuBot
- Create 6-hint framework
```

**Stage 2: Core Content** (2 hours per lesson)
```
- Flesh out all sections
- Add examples and code
- Write Apply to DocuBot Task + Outcome
- Fill in all 6 hints
- Add troubleshooting/edge cases
```

**Stage 3: Testing & Validation** (1-2 hours per lesson)
```
- Test all code examples locally
- Verify all commands work cross-platform
- Check grammar and spelling
- Verify analogies are clear
- Count concepts (ensure within A1-A2 limit)
```

**Stage 4: Quality Review** (30 min per lesson)
```
- Self-check against checklist above
- Verify constitutional alignment
- Ensure no constraint violations
- Check format compliance
- Get peer review if possible
```

**Total Time per Lesson**: 4.5-5 hours
**Total Time for Chapter 1**: 18-20 hours (4 lessons Ã— 4.5-5 hours)

---

## X. TESTING & VALIDATION STRATEGY

### Pre-Publication Testing

**Unit Tests** (per lesson):
1. **Test 1.1.1**: test_api.py runs successfully
2. **Test 1.1.2**: Valid API key produces response within 5 sec
3. **Test 1.1.3**: Invalid API key shows clear error
4. **Test 1.2.1**: Comparison table has 5+ rows per column
5. **Test 1.2.2**: Student can articulate LLM vs Agent distinction
6. **Test 1.3.1**: UV installs on macOS
7. **Test 1.3.2**: UV installs on Windows (PowerShell)
8. **Test 1.3.3**: UV installs on Linux
9. **Test 1.3.4**: project setup creates pyproject.toml + uv.lock
10. **Test 1.3.5**: .env file is accessible to Python code
11. **Test 1.3.6**: `uv add openai` completes successfully
12. **Test 1.3.7**: test_api.py works in docubot/ folder
13. **Test 1.4.1**: architecture.md has 3 sections
14. **Test 1.4.2**: Component descriptions are non-technical
15. **Test 1.4.3**: Chapter roadmap is accurate

**Integration Tests** (full chapter):
1. **Test CH-1**: Student completes all 4 lessons in 2-3 hours
2. **Test CH-2**: Student exits with working API key + environment
3. **Test CH-3**: Student understands course end goal
4. **Test CH-4**: Zero agent code written (verify codebase)

### Pilot Testing with Real Students

**Cohort Size**: 3-5 students (diverse OS: macOS, Windows, Linux)

**Pilot Metrics**:
- **Completion Rate**: % of students finishing all 4 lessons
- **Time on Task**: Actual time vs estimated 2-3 hours
- **API Success Rate**: % achieving working test_api.py
- **Environment Success Rate**: % completing full setup
- **Comprehension**: % scoring 80%+ on end quiz
- **Support Tickets**: Number of help requests per lesson

**Adjustment Criteria**:
- If <85% complete â†’ Simplify or clarify content
- If >4 hours average â†’ Reduce scope or break into 5 lessons
- If >20% API failures â†’ Improve troubleshooting guidance
- If <70% quiz scores â†’ Strengthen concept teaching

---

## XI. ROLLOUT & PUBLICATION CHECKLIST

### Pre-Publication Gate

**Quality Assurance**:
- [ ] All lessons pass technical review
- [ ] All code examples tested
- [ ] All commands verified on 3+ OSes
- [ ] Grammar and spelling perfect
- [ ] Constitutional alignment confirmed
- [ ] Acceptance tests passing

**Documentation**:
- [ ] lesson-1-1.md complete and ready
- [ ] lesson-1-2.md complete and ready
- [ ] lesson-1-3.md complete and ready
- [ ] lesson-1-4.md complete and ready
- [ ] README.md for chapter (overview, prerequisites)
- [ ] This plan.md finalized and linked

**Integration**:
- [ ] Files placed in correct directory structure:
  ```
  book-source/docs/06-AI-Native-Software-Development/
  â”œâ”€â”€ 041-intro-to-apis-agents/
  â”‚   â”œâ”€â”€ README.md
  â”‚   â”œâ”€â”€ lesson-1-1.md
  â”‚   â”œâ”€â”€ lesson-1-2.md
  â”‚   â”œâ”€â”€ lesson-1-3.md
  â”‚   â”œâ”€â”€ lesson-1-4.md
  â”‚   â””â”€â”€ quiz.md (if applicable)
  ```
- [ ] Sidebar/navigation updated in docusaurus config
- [ ] Chapter gating configured (if platform supports)
- [ ] Previous chapter links to Chapter 1

**Launch**:
- [ ] Create git branch: `041-ch01-intro-apis-agents`
- [ ] Commit all lesson files
- [ ] Create pull request with this plan.md reference
- [ ] Get approval from technical reviewer
- [ ] Merge to main
- [ ] Update course navigation
- [ ] Announce in student cohort

---

## XII. RISK MITIGATION & TROUBLESHOOTING GUIDE

### High-Risk Failure Points

**Risk 1: API Key Acquisition**
- **Problem**: Students don't have OpenAI account/API key
- **Impact**: Cannot complete Lesson 1.1, blocks progression
- **Mitigation**:
  - Provide step-by-step link to OpenAI API key creation
  - Mention free tier availability
  - Offer cloud-based alternative (if available)
- **Fallback**: Pre-generate test accounts (if allowed by OpenAI terms)

**Risk 2: UV Installation Failures**
- **Problem**: curl/PowerShell install fails due to permissions/firewall
- **Impact**: Cannot complete Lesson 1.3, blocks all future chapters
- **Mitigation**:
  - Provide pip alternative: `pip install uv`
  - Document corporate firewall workarounds
  - Provide Docker image fallback
- **Fallback**: Cloud-based dev environment (GitHub Codespaces, etc.)

**Risk 3: Network/Connectivity Issues**
- **Problem**: Student's network blocks OpenAI API calls
- **Impact**: test_api.py fails, cannot verify setup
- **Mitigation**:
  - Include troubleshooting steps for firewalls
  - Suggest VPN or alternate network
  - Provide offline conceptual understanding
- **Fallback**: Allow offline completion with mock API responses

**Risk 4: OS Compatibility**
- **Problem**: macOS/Windows/Linux specific issues
- **Impact**: Setup works on one OS but fails on another
- **Mitigation**:
  - Test on 3 OSes before publication
  - Provide OS-specific instructions clearly
  - Use python-dotenv (cross-platform)
- **Fallback**: Dedicated setup support session

**Risk 5: Python Version Mismatch**
- **Problem**: Student has Python 2.7 or old Python 3.x
- **Impact**: UV or OpenAI library fails
- **Mitigation**:
  - Clearly state Python 3.8+ requirement
  - Provide links to Python installation
  - Check with `python --version` in Lesson 1.3
- **Fallback**: Point to python.org install guide

### Common Student Questions (FAQ)

**Q: "I don't have an OpenAI account. Can I still take this course?"**
A: No, you'll need to create a free OpenAI account and get an API key. This is a one-time setup that takes 5 minutes. [Link to instructions]

**Q: "I'm on Windows and the curl command doesn't work."**
A: Use the PowerShell version instead. Windows doesn't have curl by default, but PowerShell has an equivalent command. See Windows instructions in Lesson 1.3.

**Q: "The test_api.py gives a 401 error. What does that mean?"**
A: 401 is authentication failure. Your API key is wrong/invalid/expired. Check:
1. Copy the key again from openai.com/api-keys
2. Make sure it starts with `sk-`
3. Check your .env file has no extra spaces
4. Restart your terminal after editing .env

**Q: "uv add openai is taking forever. Is it stuck?"**
A: Installation can take 1-2 minutes on slow connections. Let it finish. If it's been >5 min, check your internet and try again.

**Q: "I completed Lesson 1.3 but test_api.py still doesn't work."**
A: Check: (1) Is your API key valid in .env? (2) Does `python -c "from openai import OpenAI"` work? (3) Are you inside the docubot/ folder when running the script?

---

## XIII. SUCCESS METRICS & KPIs

### Chapter 1 Success Definition

**Student Outcomes**:
- 90%+ of enrolled students complete all 4 lessons
- 85%+ complete in 2-3 hour window
- 95%+ achieve working API key verification
- 80%+ environment setup on first attempt
- 90%+ score 80%+ on end-of-chapter quiz
- 100% have valid API key + environment before Chapter 2

**Content Quality**:
- 0 critical errors in code examples (must test all)
- 0 meta-commentary exposing pedagogical framework
- 100% constitutional alignment (all PC-*, TC-*, CSC-* satisfied)
- <5% student questions on content clarity

**Progression**:
- 90%+ successfully proceed to Chapter 2
- <10% churn rate from Chapter 1 to 2
- Average time in Chapter 1: 2.5 hours

**Instructor Load**:
- <20 support tickets total for Chapter 1
- <5 tickets on content (rest on personal setup)
- <30 min average support response time

---

## XIV. NEXT STEPS & HANDOFF

### Immediate Actions (Content Implementer)

1. **Week 1: Skeleton & Planning**
   - [ ] Copy lesson templates
   - [ ] Fill in all Learning Goals, Concepts, Key Points
   - [ ] Create rough analogy boxes
   - [ ] Outline all Apply to DocuBot sections

2. **Week 2: Core Content**
   - [ ] Write detailed explanations
   - [ ] Create all code examples
   - [ ] Write all 6 hints per lesson
   - [ ] Add troubleshooting sections

3. **Week 3: Testing & Validation**
   - [ ] Test all code on macOS
   - [ ] Test all code on Windows
   - [ ] Test all code on Linux
   - [ ] Verify all commands work
   - [ ] Check grammar and formatting

4. **Week 4: Quality Review**
   - [ ] Self-review against checklist
   - [ ] Peer review with team
   - [ ] Final polish and publication
   - [ ] Prepare for technical review

### Downstream Handoffs

**To Technical Reviewer**:
- [ ] All 4 lesson .md files
- [ ] test_api.py validated
- [ ] Installation commands tested
- [ ] This plan.md for reference

**To Chapter 2 Planner**:
- This plan.md (context for sequential design)
- Validated test_api.py (starting point for Chapter 2)
- architecture.md template (for reference in future chapters)

**To Platform Team**:
- Lesson files for publishing
- Chapter gating configuration
- Prerequisites for Chapter 2
- Support FAQ

---

## XV. APPENDIX: QUICK REFERENCE

### Files to Create
```
âœ… /mnt/c/Users/HP/Documents/colearning-python/book-source/docs/06-AI-Native-Software-Development/041-intro-apis-agents/
  â”œâ”€â”€ README.md (chapter overview, ~500 words)
  â”œâ”€â”€ lesson-1-1.md (API Fundamentals, ~2000 words)
  â”œâ”€â”€ lesson-1-2.md (LLM vs Agent, ~1800 words)
  â”œâ”€â”€ lesson-1-3.md (Environment Setup, ~2500 words)
  â”œâ”€â”€ lesson-1-4.md (Architecture Overview, ~2000 words)
  â””â”€â”€ quiz.md (optional: end-of-chapter assessment)
```

### Word Count Estimates
- Lesson 1.1: ~2000 words (30 min read + 10 min exercises)
- Lesson 1.2: ~1800 words (25 min read + 15 min exercises)
- Lesson 1.3: ~2500 words (25 min read + 25 min setup)
- Lesson 1.4: ~2000 words (20 min read + 15 min documentation)
- **Total**: ~8300 words

### Markdown Template Structure
```markdown
# Lesson X.Y: [Title]

## Learning Goal
[2 min read]

## What You'll Learn
[3 min read]

## Key Points
[5 min read]

## Simple Analogy
[2-3 min read + visual]

## Code Level
[1 min explanation]

## Apply to DocuBot Project

### Task
[Numbered steps]

### Outcome
[Italicized achievement]

## Hints
[6 progressive hints]

## Starter Code (if applicable)
[Code block]

## Troubleshooting
[Common issues + solutions]
```

---

**IMPLEMENTATION PLAN COMPLETE**

This plan provides all necessary details for content implementers to create all 4 lessons with proper pedagogical structure, full compliance with specification and constitution, and clear success criteria.

**Ready for handoff to content implementation team.**

---

*Plan created: 2025-12-06*
*Plan version: 1.0.0*
*Status: Ready for Implementation*
