---
id: chapter-11-sensors-simulation
title: 'Chapter 11: Sensors in Simulation'
sidebar_position: 11
sidebar_label: 11. Sensors in Simulation
description: >-
  Simulating cameras, LIDAR, IMU, and contact sensors in Gazebo for robotics
  perception
---


# باب 11: سمولیشن میں سینسرز (Sensors in Simulation)

روبوٹس اپنے ماحول کو سینسرز کے ذریعے محسوس کرتے ہیں۔ ایک کیمرہ تصاویر لیتا ہے، LIDAR فاصلے ماپتا ہے، ایک IMU سمت اور ایکسلریشن (acceleration) کو ٹریک کرتا ہے، کانٹیکٹ سینسرز (contact sensors) ٹکراؤ کا پتہ لگاتے ہیں۔ حقیقی دنیا میں، ان سینسرز کو شامل کرنے کے لیے ہارڈ ویئر کی مہارت اور احتیاط سے کیلیبریشن (calibration) کی ضرورت ہوتی ہے۔ سمولیشن میں، آپ انہیں SDF کی چند لائنوں سے ترتیب (configure) دیتے ہیں۔

اس باب میں، آپ Gazebo میں سمولیٹڈ روبوٹس میں حقیقی سینسرز شامل کریں گے۔ آپ ویژن (vision) کے کاموں کے لیے کیمرے، نیویگیشن اور میپنگ کے لیے LIDAR سکینرز، سمت کے لیے انرشیل میژرمنٹ یونٹس (IMUs)، اور ٹکراؤ کا پتہ لگانے کے لیے ٹچ سینسرز کو ترتیب دیں گے۔ اختتام تک، آپ سمجھ جائیں گے کہ سمولیٹڈ سینسر ڈیٹا روبوٹ کے رویے کو کیسے چلاتا ہے—اور جب سینسرز خراب کام کریں تو ڈیبگ (debug) کیسے کریں۔

**مدت**: 4 اسباق، کل 4 گھنٹے
**لئیر بریک ڈاؤن**: L1: 60%، L2: 40% (ڈیبگنگ اور AI تعاون)
**ہارڈ ویئر ٹئیر**: ٹئیر 1 (کلاؤڈ Gazebo)، ٹئیر 2 (ایڈوانسڈ رینڈرنگ کے لیے لوکل GPU)
**مطلوبہ پیشگی علم**: باب 10 (Gazebo کی بنیادی باتیں، روبوٹ ماڈلز، URDF/SDF)
**دوبارہ استعمال کے قابل مہارتیں**: `sensor-simulation`, `sensor-debugging`

## سیکھنے کے مقاصد

اس باب کے اختتام تک، آپ اس قابل ہو جائیں گے کہ:

- روبوٹ ماڈلز میں **کیمرہ سینسرز شامل کریں** اور Gazebo میں ویڈیو سٹریمز دیکھیں
- فاصلے کی پیمائش اور 3D پوائنٹ کلاؤڈز کے لیے **LIDAR سینسرز ترتیب دیں**
- سمت کو ٹریک کرنے کے لیے **IMU سینسرز سیٹ اپ کریں**
- ٹکراؤ اور چھونے کا پتہ لگانے کے لیے **کانٹیکٹ سینسرز نافذ کریں**
- حقیقی سمولیشن کے لیے **سینسر نائز ماڈلز (sensor noise models) کو سمجھیں**
- Gazebo ویژولائزیشن ٹولز اور AI تعاون کا استعمال کرتے ہوئے **سینسر کے مسائل ڈیبگ کریں**
- روبوٹ کی نیویگیشن اور مینیپولیشن کی رہنمائی کے لیے **سینسر ڈیٹا کا اطلاق کریں**

## اسباق

### سبق 11.1: کیمرہ سمولیشن (60 منٹ)

اپنے روبوٹ میں کیمرہ سینسر شامل کریں۔ کیمرے ایک سمولیٹڈ نقطہ نظر سے تصاویر کیپچر کرتے ہیں، جس سے آبجیکٹ ڈیٹیکشن، لین فالونگ، یا گیسچر ریکگنیشن جیسے ویژن پر مبنی کام ممکن ہو جاتے ہیں۔ کیمرہ پیرامیٹرز سیکھیں: ریزولوشن، فیلڈ آف ویو (FOV)، نیئر اور فار کلپ پلینز، اور فریم ریٹ۔

**بنیادی تصورات**:
- کیمرہ سینسر SDF ڈھانچہ
- کیمرہ پیرامیٹرز (ریزولوشن، FOV، فریم ریٹ)
- Gazebo GUI میں کیمرہ آؤٹ پٹ دیکھنا
- کیمرہ ٹاپکس (`/camera/image`, `/camera/camera_info`)
- لئیر: L1 (دستی بنیاد)

---

### سبق 11.2: LIDAR سمولیشن (60 منٹ)

فاصلے کی پیمائش اور 3D پرسیپشن کے لیے LIDAR سکینر کو ترتیب دیں۔ LIDAR نیویگیشن، رکاوٹ سے بچنے، اور SLAM (Simultaneous Localization and Mapping) کے لیے ضروری ہے۔ 2D لیڈر (لیزر رینج فائنڈرز) اور 3D پوائنٹ کلاؤڈز (Velodyne طرز) کے بارے میں جانیں۔

**بنیادی تصورات**:
- LIDAR سینسر SDF ڈھانچہ
- رینج پیرامیٹرز (کم از کم/زیادہ سے زیادہ فاصلہ، اینگل سویپ)
- نمونے (Samples) اور ریزولوشن
- ویژولائزیشن (Gazebo میں پوائنٹ کلاؤڈ ڈسپلے)
- LIDAR ٹاپکس (`/lidar/scan`, `/lidar/points`)
- حقیقی ڈیٹا کے لیے نائز ماڈلز
- لئیر: L1 (دستی بنیاد)

---

### سبق 11.3: IMU اور کانٹیکٹ سینسرز (60 منٹ)

سمت اور ایکسلریشن کو ٹریک کرنے کے لیے انرشیل میژرمنٹ یونٹس (IMUs) شامل کریں۔ جب آپ کا روبوٹ اشیاء کو چھوتا ہے تو اس کا پتہ لگانے کے لیے کانٹیکٹ سینسرز شامل کریں۔ یہ سینسر توازن، نیویگیشن، اور مینیپولیشن کے لیے ضروری فیڈ بیک فراہم کرتے ہیں۔

**بنیادی تصورات**:
- IMU سینسر ڈھانچہ (ایکسیلرو میٹر، جائرو اسکوپ، میگنیٹو میٹر)
- IMU ڈیٹا سٹریمز (لینیئر ایکسلریشن، اینگولر ویلاسٹی، اورینٹیشن)
- نائز اور بائس ماڈلز
- کانٹیکٹ سینسر کی ترتیب
- کانٹیکٹ سینسر آؤٹ پٹ اور ٹرگرنگ
- لئیر: L1 (دستی بنیاد)

---

### سبق 11.4: سینسر ڈیبگنگ اور ویژولائزیشن (60 منٹ)

سینسر خراب ہو جاتے ہیں۔ شاید ایک کیمرہ تمام سیاہ فریم شائع کر رہا ہو۔ شاید LIDAR صفر واپس کر رہا ہے۔ شاید IMU ڈیٹا بہہ رہا ہے۔ Gazebo ٹولز اور AI تعاون کا استعمال کرتے ہوئے سینسر کنفیگریشن کے مسائل کی تشخیص اور انہیں ٹھیک کرنا سیکھیں تاکہ آپ کے ڈیبگنگ کے انداز کو بہتر بنایا جا سکے۔

**بنیادی تصورات**:
- عام سینسر کے مسائل (شائع نہ ہونا، صفر شائع کرنا، شور والا ڈیٹا)
- Gazebo تشخیصی ٹولز (ٹاپک ایکو، پلاٹ، پوائنٹ کلاؤڈ ڈسپلے)
- ڈیبگنگ ورک فلو (کنفیگریشن چیک کریں، آؤٹ پٹ چیک کریں، پیرامیٹرز کو بہتر بنائیں)
- ڈیبگنگ میں پارٹنر کے طور پر AI (مسئلہ بیان کریں، تجاویز حاصل کریں، جانچ کریں، بہتر بنائیں)
- لئیر: L2 (AI تعاون، تھری رولز فریم ورک پوشیدہ)

---

## 4-لئیر تدریسی طریقہ

| لئیر | % | کیا کور کیا گیا ہے |
|-------|---|----------------|
| **L1: دستی** | 60% | SDF سینسر کنفیگریشن، ہر سینسر قسم کا دستی واک تھرو، GUI میں جانچ |
| **L2: AI تعاون** | 40% | AI کے ساتھ ڈیبگنگ، فیڈ بیک کی بنیاد پر سینسر کنفیگریشن کو بہتر بنانا، پیرامیٹرز کو آپٹمائز کرنا |
| **L3: انٹیلی جنس** | 0% | یہ باب نہیں (سینسر پیٹرن لاگو کیے جا رہے ہیں، ڈیزائن نہیں کیے جا رہے) |
| **L4: تفصیلات پر مبنی** | 0% | یہ باب نہیں (سینسرز اجزاء ہیں، مکمل نظام نہیں) |

یہ باب **سینسر کنفیگریشن اور ڈیبگنگ میں مہارت حاصل کرنے** پر مرکوز ہے۔ آپ نئے سینسر ڈیزائن نہیں کر رہے ہیں—آپ موجودہ کو مربوط کر رہے ہیں اور ٹروبل شوٹ کرنا سیکھ رہے ہیں۔

## ہارڈ ویئر کی ضروریات

**کم از کم ٹئیر**: ٹئیر 1 (TheConstruct کے ذریعے کلاؤڈ Gazebo)

| ٹئیر | آلات | آپ کیا کر سکتے ہیں |
|------|-----------|-----------------|
| **1** | لیپ ٹاپ + براؤزر | بنیادی رینڈرنگ کے ساتھ کلاؤڈ Gazebo، تمام سینسرز کی حمایت |
| **2** | RTX GPU | ایڈوانسڈ کیمرہ رینڈرنگ (رے ٹریسنگ، ہائی ریزولوشن) کے ساتھ لوکل Gazebo |

تمام بنیادی مشقیں ٹئیر 1 پر کام کرتی ہیں۔ ٹئیر 2 اعلیٰ وفاداری والے کیمرہ سمولیشن کو فعال کرتا ہے لیکن سیکھنے کے لیے ضروری نہیں ہے۔

## مطلوبہ پیشگی علم

- **باب 10** (Gazebo کی بنیادی باتیں، روبوٹ ماڈلز، SDF/URDF)
- **ROS 2 ٹاپکس اور میسجز کی سمجھ**
- **SDF XML سنٹیکس کے ساتھ واقفیت**

## مہارت کا گیٹ

**باب 12** (ایڈوانسڈ سمولیشن) پر جانے سے پہلے، آپ اس قابل ہونے چاہئیں کہ:

- مخصوص ریزولوشن، FOV، اور فریم ریٹ کے ساتھ روبوٹ میں **کیمرہ سینسر شامل کریں**
- مخصوص رینج، اینگل سویپ، اور نمونہ کثافت کے ساتھ **LIDAR سینسر شامل کریں**
- نائز پیرامیٹرز کے ساتھ **IMU سینسر ترتیب دیں**
- ٹکراؤ کا پتہ لگانے کے لیے **کانٹیکٹ سینسر شامل کریں**
- Gazebo میں سینسر آؤٹ پٹ کو ویژولائز کریں (کیمرہ امیجز، پوائنٹ کلاؤڈز، ڈیٹا پلاٹس)
- Gazebo ٹولز اور ڈیبگنگ ورک فلو کا استعمال کرتے ہوئے **سینسر کے مسائل کی تشخیص کریں**
- آؤٹ پٹ ویلیڈیشن کی بنیاد پر سینسر کنفیگریشن کو بہتر بنانے کے لیے **AI کے ساتھ کام کریں**

اگر آپ یہ کر سکتے ہیں، تو آپ سمولیشن کے مزید ایڈوانسڈ موضوعات کے لیے تیار ہیں۔

---

## کلیدی پیٹرنز (Key Patterns)

### کیمرہ پیٹرن (ویژن)
```
Robot → Camera Sensor → Image Topic → Vision Node
استعمال برائے: آبجیکٹ ڈیٹیکشن، ویژول سرونگ، لین فالونگ، انسانی تعامل
```

### LIDAR پیٹرن (پرسیپشن)
```
Robot → LIDAR Sensor → Point Cloud Topic → Navigation Node
استعمال برائے: 3D میپنگ، رکاوٹ سے بچنا، SLAM، آبجیکٹ کی شناخت
```

### IMU پیٹرن (اورینٹیشن)
```
Robot → IMU Sensor → IMU Data Topic → Balance/Navigation Node
استعمال برائے: سیلف رائٹنگ، چلنے کا استحکام، انرشیل نیویگیشن
```

### کانٹیکٹ پیٹرن (چھونا)
```
Robot → Contact Sensor → Contact Event Topic → Manipulation Node
استعمال برائے: گرفت کا پتہ لگانا، ٹکراؤ کا ردعمل، خطہ کا پتہ لگانا
```

---

## سینسر کنفیگریشن چیک لسٹ

اپنے روبوٹ میں کوئی بھی سینسر شامل کرتے وقت:

1. روبوٹ کی SDF فائل میں سینسر کی تعریف کریں
2. سینسر کے پیرامیٹرز (ریزولوشن، رینج، اپ ڈیٹ ریٹ) کی وضاحت کریں
3. مناسب ٹرانسفارمز (ماؤنٹنگ پوزیشن اور سمت) سیٹ کریں
4. حقیقت پسندی کے لیے نائز ماڈلز کو ترتیب دیں
5. تصدیق کریں کہ سینسر شائع ہو رہا ہے (`gz topic` کے ساتھ ٹاپکس چیک کریں)
6. Gazebo GUI میں آؤٹ پٹ کو ویژولائز کریں
7. اگر آؤٹ پٹ غیر متوقع ہے تو ڈیبگ کریں (صفر، سب سیاہ، کوئی پیغام نہیں)
8. سینسر ڈیٹا کو اپنے کنٹرول نوڈز میں مربوط کریں

---

## نیویگیشن

**پچھلا باب**: [← باب 10: سمولیشن کی دنیا بنانا](../chapter-10-simulation-worlds/README.md)

**اگلا باب**: [باب 12: ROS 2 + Gazebo انٹیگریشن →](../chapter-12-ros2-gazebo-integration/README.md)

**ماڈیول کا جائزہ**: [← ماڈیول 2 پر واپس](../README.md)

**سبق 11.1 شروع کریں**: [کیمرہ سمولیشن →](./01-camera-simulation.md)